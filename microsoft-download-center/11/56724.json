{
    "error": "",
    "downloadTitle": "Translator Human Parity Data",
    "downloadDescription": "Human evaluation results and translation output for the Translator Human Parity Data release.",
    "downloadFile": [
        {
            "isPrimary": "False",
            "name": "Translator-HumanParityData-v1.0.zip",
            "url": "https://download.microsoft.com/download/4/f/3/4f3f0c58-bf49-4bb7-b388-0f77ab942309/Translator-HumanParityData-v1.0.zip",
            "size": "1404768",
            "version": "1.0",
            "datePublished": "7/15/2024 4:57:20 AM"
        }
    ],
    "localeDropdown": [
        {
            "cultureCode": "en-us",
            "name": "English"
        }
    ],
    "detailsSection": "Human evaluation results and translation output for the Translator Human Parity Data release, as described in <a href=\"https://blogs.microsoft.com/ai/machine-translation-news-test-set-human-parity/\">https://blogs.microsoft.com/ai/machine-translation-news-test-set-human-parity/</a>\r\n<br /><br />\r\nThe Translator Human Parity Data release contains all human evaluation results and translations related to our paper \"Achieving Human Parity on Automatic Chinese to English News Translation\", published on March 14, 2018. We have released this data to 1) allow external validation of our claim of having achieved human parity and 2) to foster future research by releasing two additional human references for the Reference-WMT test set.\r\n<br /><br />\r\nThe package includes 1) two new references for newstest2017, one based on human translation from scratch (Reference-HT), the other based on human post-editing (Reference-PE); 2) human parity translations generated by our research systems Combo-4, Combo-5, and Combo-6, as well as translation output from online machine translation service Online-A-1710, collected on October 16, 2017; and 3) all data points collected in our human evaluation campaigns. This includes annotations for Subset-1, Subset-2, Subset-3, and Subset-4. We share the (anonymized) annotator IDs, segment IDs, system IDs, type ID (either TGT or CHK, the second being a repeated judgment for the first), raw scores r in [0,100], as well as annotation start and end times. Additionally, we share the combined data for Meta-1 campaign on Subset-1. \r\n<br /><br />\r\nWhen using this data we require that you cite our paper, which is available here: <a href=\"https://www.microsoft.com/en-us/research/publication/achieving-human-parity-on-automatic-chinese-to-english-news-translation/\">https://www.microsoft.com/en-us/research/publication/achieving-human-parity-on-automatic-chinese-to-english-news-translation/</a>\r\n",
    "detailsSection_kbArticles": {
        "link": "http://support.microsoft.com/kb/",
        "name": ""
    },
    "detailsSection_securityBulletins": {
        "link": "http://technet.microsoft.com/en-us/security/Bulletin/",
        "name": ""
    },
    "detailsSection_file_version": "1.0",
    "detailsSection_file_name": [
        "Translator-HumanParityData-v1.0.zip"
    ],
    "detailsSection_file_size": [
        "1.3 MB"
    ],
    "detailsSection_file_date": "7/15/2024",
    "systemRequirementsSection": "<UL><LI>Windows 10</LI></UL>",
    "systemRequirementsSection_supportedOS": [
        "Windows 10"
    ],
    "installInstructionSection": "<UL><LI>Click <B>Download</B> and follow the instructions. </LI></UL>",
    "relatedResourcesSection": [],
    "locale": "en-us",
    "detailsId": "56724",
    "downloadPreload": true
}